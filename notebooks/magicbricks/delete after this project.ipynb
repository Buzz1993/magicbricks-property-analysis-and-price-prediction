{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03605593-6b72-42e4-8568-d7a2a82c736e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#how to handle one column using another column using labmda \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#convert sqm and kanal to sqft\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#sqft=sqm×10.7639\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#sqft=kanal×5,445\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10.7639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msqm\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marea_unit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkanal\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost_per_unit\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     13\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#how to handle one column using another column using labmda \n",
    "\n",
    "#convert sqm and kanal to sqft\n",
    "#sqft=sqm×10.7639\n",
    "#sqft=kanal×5,445\n",
    "\n",
    "df['cost_per_unit'] = df['cost_per_unit'].str.replace(',', '').astype(float)\n",
    "\n",
    "df['cost_per_unit'] = df.apply(\n",
    "    lambda row: row['cost_per_unit'] * 10.7639 if row['area_unit'] == 'sqm' \n",
    "    else row['cost_per_unit'] * 5445 if row['area_unit'] == 'kanal'\n",
    "    else row['cost_per_unit'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda5eaa8-54da-4090-b752-90c37c0a1255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            raw_data extracted_number_lambda\n",
      "0  sqftsqftsqyrdsqmacrebighahectaremarlakanalbisw...                     NaN\n",
      "1                                               None                     NaN\n",
      "2  623sqftsqftsqyrdsqmacrebighahectaremarlakanalb...                     623\n",
      "3  702sqftsqftsqyrdsqmacrebighahectaremarlakanalb...                     702\n",
      "4  608sqftsqftsqyrdsqmacrebighahectaremarlakanalb...                     608\n",
      "5  0sqftsqftsqyrdsqmacrebighahectaremarlakanalbis...                       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Data provided by the user\n",
    "data = [\n",
    "    \"sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,346/sqft\",\n",
    "    None,\n",
    "    \"623sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,892/sqft\",\n",
    "    \"702sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹23,500/sqft\",\n",
    "    \"608sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹20,724/sqft\",\n",
    "    \"0sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹20,724/sqft\"\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"raw_data\"])\n",
    "\n",
    "# Using a lambda function to extract numeric values\n",
    "df[\"extracted_number_lambda\"] = df[\"raw_data\"].apply(\n",
    "    lambda value: re.match(r\"^[\\d,]+\\.*[\\d]*\", value).group(0) if pd.notna(value) and re.match(r\"^[\\d,]+\\.*[\\d]*\", value) else np.nan\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3732ee0-1e0e-4989-8ab6-208271067689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      635.0\n",
      "1     1905.0\n",
      "2      623.0\n",
      "3      702.0\n",
      "4      608.0\n",
      "5      770.0\n",
      "6     1350.0\n",
      "7        NaN\n",
      "8     3700.0\n",
      "9        0.0\n",
      "10       NaN\n",
      "11     943.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    \"635 Sq-ft\", \n",
    "    \"1905 Sq-ft\", \n",
    "    \"623 Sq-ft\", \n",
    "    \"702 Sq-ft\", \n",
    "    \"608 Sq-ft\", \n",
    "    \"770 Sq-ft\", \n",
    "    \"1350 Sq-ft\", \n",
    "    np.nan, \n",
    "    \"37,00.0 Sq-ft\", \n",
    "    \"0Sq-ft\", \n",
    "    \"Sq-ft\", \n",
    "    \"9,43 Sq-ft\"\n",
    "]\n",
    "\n",
    "# Convert data to a pandas Series for easier manipulation\n",
    "series = pd.Series(data)\n",
    "\n",
    "# Lambda function to extract numeric value or return np.nan\n",
    "series_extracted = series.apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if isinstance(x, str) and re.match(r'([\\d,\\.]+)', x) else np.nan)\n",
    "\n",
    "# Result\n",
    "print(series_extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "abb16693-315c-46c5-bc32-3f5cb8a928af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            raw_data  extracted_number_lambda\n",
      "0  1sqftsqftsqyrdsqmacrebighahectaremarlakanalbis...                     1.00\n",
      "1                                               None                      NaN\n",
      "2  62,,3sqftsqftsqyrdsqmacrebighahectaremarlakana...                   623.00\n",
      "3  7.02sqftsqftsqyrdsqmacrebighahectaremarlakanal...                     7.02\n",
      "4  6,0.8sqftsqftsqyrdsqmacrebighahectaremarlakana...                    60.80\n",
      "5  0sqftsqftsqyrdsqmacrebighahectaremarlakanalbis...                     0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Data provided by the user\n",
    "data = [\n",
    "    \"1sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,346/sqft\",\n",
    "    None,\n",
    "    \"62,,3sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,892/sqft\",\n",
    "    \"7.02sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹23,500/sqft\",\n",
    "    \"6,0.8sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹20,724/sqft\",\n",
    "    \"0sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹20,724/sqft\"\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"raw_data\"])\n",
    "\n",
    "# Using a lambda function to extract numeric values\n",
    "#df[\"extracted_number_lambda\"] = df[\"raw_data\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if isinstance(x, str) and re.match(r'([\\d,\\.]+)', x) else np.nan)\n",
    "df[\"extracted_number_lambda\"] = df[\"raw_data\"].apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else np.nan)\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a074d22a-ed20-49d9-acb7-481c02eacd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      635.00\n",
      "1     1905.00\n",
      "2      623.00\n",
      "3      702.00\n",
      "4      608.00\n",
      "5      770.00\n",
      "6        0.35\n",
      "7         NaN\n",
      "8     3700.00\n",
      "9        0.00\n",
      "10        NaN\n",
      "11     943.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    \"635 Sq-ft\", \n",
    "    \"1905 Sq-ft\", \n",
    "    \"623 Sq-ft\", \n",
    "    \"702 Sq-ft\", \n",
    "    \"608 Sq-ft\", \n",
    "    \"770 Sq-ft\", \n",
    "    \"0.350 Sq-ft\", \n",
    "    np.nan, \n",
    "    \"37,00.0 Sq-ft\", \n",
    "    \"0Sq-ft\", \n",
    "    \"Sq-ft\", \n",
    "    \"9,43 Sq-ft\"\n",
    "]\n",
    "\n",
    "# Convert data to a pandas Series for easier manipulation\n",
    "series = pd.Series(data)\n",
    "\n",
    "# Lambda function to extract numeric value or return np.nan\n",
    "series_extracted = series.apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else np.nan)\n",
    "\n",
    "# Result\n",
    "print(series_extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7c7a15f-8e4e-4d30-ba98-ba5977482cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       area_work  cost_per_sqft\n",
      "0      ₹346/sqft        346.000\n",
      "1    ₹0.892/sqft          0.892\n",
      "2   ₹23,500/sqft      23500.000\n",
      "3   ₹20,724/sqft      20724.000\n",
      "4  ₹20,72.4/sqft       2072.400\n",
      "5          ₹sqft            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    \"₹346/sqft\",\n",
    "    \"₹0.892/sqft\",\n",
    "    \"₹23,500/sqft\",\n",
    "    \"₹20,724/sqft\",\n",
    "    \"₹20,72.4/sqft\",\n",
    "    \"₹sqft\"\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"area_work\"])\n",
    "\n",
    "# Extract cost per square foot, clean commas and convert to numeric\n",
    "df['cost_per_sqft'] = df['area_work'].str.extract(r'₹([\\d,\\.]+)')[0].str.replace(',', '').astype(float)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab990e78-f4d5-49c1-a1d6-996733666ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        area_work area_unit\n",
      "0    ₹28,346/sqft      sqft\n",
      "1    ₹28,892/sqft      sqft\n",
      "2    ₹23,500/sqft      sqft\n",
      "3    ₹20,724/sqft      sqft\n",
      "4  ₹20,72.4/kamal     kamal\n",
      "5             sqm       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    \"₹28,346/sqft\",\n",
    "    \"₹28,892/sqft\",\n",
    "    \"₹23,500/sqft\",\n",
    "    \"₹20,724/sqft\",\n",
    "    \"₹20,72.4/kamal\n",
    "    \",\n",
    "    \"sqft\"\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"area_work\"])\n",
    "\n",
    "df['area_unit'] = df['area_work'].str.extract(r'/([^/]+)$')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffd6b3-28cd-4b69-9176-858c587f96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    \"635 Sq-ft\", \n",
    "    \"1905 Sq-ft\", \n",
    "    \"623 Sq-ft\", \n",
    "    \"702 Sq-ft\", \n",
    "    \"608 Sq-ft\", \n",
    "    \"770 Sq-ft\", \n",
    "    \"0.350 Sq-ft\", \n",
    "    np.nan, \n",
    "    \"37,00.0 Sq-ft\", \n",
    "    \"0Sq-ft\", \n",
    "    \"Sq-ft\", \n",
    "    \"9,43 Sq-ft\"\n",
    "]\n",
    "\n",
    "# Convert data to a pandas Series for easier manipulation\n",
    "series = pd.Series(data)\n",
    "\n",
    "# Lambda function to extract numeric value or return np.nan\n",
    "series_extracted = series.apply(lambda x: float(re.match(r'([\\d,\\.]+)', x).group(1).replace(',', '')) if pd.notna(x) and re.match(r'^[\\d,\\.]+', x) else np.nan)\n",
    "\n",
    "# Result\n",
    "print(series_extracted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6320f803-0b83-4806-be61-a598a01e063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Column Extracted\n",
      "0  635sqftsqftsqyrdsqmacrebighahectaremarlakanalb...      sqft\n",
      "1                                                NaN       NaN\n",
      "2  623sqftsqftsqyrdsqmacrebighahectaremarlakanalb...      sqft\n",
      "3  702sqftsqftsqyrdsqmacrebighahectaremarlakanalb...      sqft\n",
      "4  608sqftsqftsqyrdsqmacrebighahectaremarlakanalb...      sqft\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Example data\n",
    "data = [\n",
    "    \"635sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,346/sqft\",\n",
    "    np.nan,\n",
    "    \"623sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹28,892/sqft\",\n",
    "    \"702sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹23,500/sqft\",\n",
    "    \"608sqftsqftsqyrdsqmacrebighahectaremarlakanalbiswa1biswa2groundaankadamroodchatakkottahmarlacentperchgunthaarekathagajkillakuncham₹20,724/sqft\"\n",
    "]\n",
    "\n",
    "# Creating DataFrame\n",
    "df = pd.DataFrame(data, columns=['Column'])\n",
    "\n",
    "# Using lambda function to extract the first 4 alphabetic characters after the digits\n",
    "df['Extracted'] = df['Column'].apply(lambda x: ''.join([char for char in str(x)[re.match(r'\\d+', str(x)).end():] if char.isalpha()])[:4] if isinstance(x, str) else np.nan)\n",
    "\n",
    "# Showing result\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63628352-3217-43f9-91ad-80ff1f96d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for this code I write this next cell code in function \n",
    "\n",
    "#add dupli_f_area data into f_area\n",
    "df['f_area'] = np.where(\n",
    "    pd.isna(df['f_area']) & pd.notna(df['Area']),\n",
    "    df['dupli_f_area'],\n",
    "    df['f_area']\n",
    ")\n",
    "\n",
    "#add dupli_costpersqft into f_costpersqft \n",
    "df['f_costpersqft'] = np.where(\n",
    "    pd.isna(df['f_area']) & pd.notna(df['Area']),\n",
    "    df['dupli_costpersqft'],\n",
    "    df['f_costpersqft']\n",
    ")\n",
    "\n",
    "#add dupli_f_area_unit into f_area_unit \n",
    "df['f_area_unit'] = np.where(\n",
    "    pd.isna(df['f_area']) & pd.notna(df['Area']),\n",
    "    df['dupli_f_area_unit'],\n",
    "    df['f_area_unit']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883b0b69-ee00-4341-ade6-d363c5f43044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_values(df, update_cols, using_cols):\n",
    "    for update_col, using_col in zip(update_cols, using_cols):\n",
    "        df[update_col] = np.where(\n",
    "            pd.isna(df['f_area']) & pd.notna(df['Area']),\n",
    "            df[using_col],\n",
    "            df[update_col]\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Define columns to update and corresponding columns to use\n",
    "columns_to_update = ['f_costpersqft', 'f_area_unit', 'f_area']\n",
    "using_columns = ['dupli_costpersqft', 'dupli_f_area_unit', 'dupli_f_area']\n",
    "\n",
    "# Update the DataFrame\n",
    "df = update_values(df, columns_to_update, using_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e772ee8a-b1e8-4916-9eab-5e7613a58f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lift\n",
      "0   4.0\n",
      "1   NaN\n",
      "2   2.0\n",
      "3   NaN\n",
      "4   1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {\n",
    "    'lift': [\n",
    "        [4.0, np.nan, np.nan, np.nan, np.nan],\n",
    "        [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        [2.0, 2.0, np.nan, np.nan, np.nan],\n",
    "        [np.nan, np.nan, np.nan, np.nan, np.nan],\n",
    "        [np.nan, 1.0, np.nan, 1.0, np.nan]\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply transformation to each row in the 'lift' column\n",
    "df['lift'] = df['lift'].apply(lambda row: next((val for val in row if not np.isnan(val)), np.nan))\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67c273ed-b188-49df-a3e4-c52570d137ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['lift'] = df['lift'].apply(\n",
    "    lambda x: [item if isinstance(item, (int, float)) else np.nan for item in x]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "404b165e-97f6-4c4d-8b6a-5585c8b9b7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1.0, 1.0, 25.0, 7.0]\n",
       "1    [nan, 2.0, 30.0, 5.0]\n",
       "2    [3.0, 3.0, 35.0, 2.0]\n",
       "3     [nan, nan, nan, nan]\n",
       "Name: lift, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4249b2-9cc5-4f0c-9a26-457d8700407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 bed\n",
      "0  [(100.0, 500.0, nan), (200.0, nan, 40.0), (nan...\n",
      "1  [(100.0, 500.0, nan), (200.0, nan, 40.0), (nan...\n",
      "2  [(100.0, 500.0, nan), (200.0, nan, 40.0), (nan...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'AM_sales': [100, 200, None],\n",
    "    'AM_revenue': [500, None, 700],\n",
    "    'PM_sales': [50, 60, 70],\n",
    "    'AM_profit': [None, 40, 50],\n",
    "    'other_column': [1, 2, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Combine values from columns that start with 'AM', excluding NaN values\n",
    "df['bed'] = [\n",
    "    [value for value in zip(*[df[col] for col in df.columns if col.startswith('AM')]) if pd.notna(value)]\n",
    "    for row in zip(*[df[col] for col in df.columns if col.startswith('AM')])\n",
    "]\n",
    "\n",
    "# Display the result\n",
    "print(df[['bed']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acaa45f9-db07-43c8-8a0e-e12d7513954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                status        construction\n",
      "0   under construction  under construction\n",
      "1   under construction  under construction\n",
      "2   under construction  under construction\n",
      "3   under construction  under construction\n",
      "4   under construction  under construction\n",
      "5        ready to move                None\n",
      "6   under construction  under construction\n",
      "7   under construction  under construction\n",
      "8   under construction  under construction\n",
      "9   under construction  under construction\n",
      "10  under construction  under construction\n",
      "11  under construction  under construction\n",
      "12  under construction  under construction\n",
      "13  under construction  under construction\n",
      "14  under construction  under construction\n",
      "15  under construction  under construction\n",
      "16  under construction  under construction\n",
      "17  under construction  under construction\n",
      "18  under construction  under construction\n",
      "19  under construction  under construction\n",
      "20  under construction  under construction\n",
      "21  under construction  under construction\n",
      "22  under construction  under construction\n",
      "23                None  under construction\n",
      "24                None  under construction\n",
      "25                None  under construction\n",
      "26                None  under construction\n",
      "27       ready to move                None\n",
      "28                None  under construction\n",
      "29       ready to move   Less than 5 years\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the DataFrame\n",
    "data = {\n",
    "    'status': [\n",
    "        'under construction', 'under construction', 'under construction', 'under construction', \n",
    "        'under construction', 'ready to move', 'under construction', 'under construction', \n",
    "        'under construction', 'under construction', 'under construction', 'under construction', \n",
    "        'under construction', 'under construction', 'under construction', 'under construction', \n",
    "        'under construction', 'under construction', 'under construction', 'under construction', \n",
    "        'under construction', 'under construction', 'under construction', None, None, None, None,\n",
    "        'ready to move', None, 'ready to move'\n",
    "    ],\n",
    "    'construction': [\n",
    "        None, None, None, None, None, None, None, None, None, None, None, None, None, None, \n",
    "        None, None, None, None, None, None, None, None, None, 'under construction', 'under construction', \n",
    "        'under construction', 'under construction', None, 'under construction', 'Less than 5 years'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the transformation\n",
    "df['construction'] = df.apply(\n",
    "    lambda row: 'under construction' if row['status'] == 'under construction' else row['construction'], axis=1\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c6e5679-8e0d-4706-8963-a533ba112e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMI</th>\n",
       "      <th>converted_emi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81k</td>\n",
       "      <td>0.81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.07L</td>\n",
       "      <td>1.07000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81k</td>\n",
       "      <td>0.81000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74k</td>\n",
       "      <td>0.74000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57k</td>\n",
       "      <td>0.57000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56k</td>\n",
       "      <td>0.56000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45k</td>\n",
       "      <td>0.45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15k</td>\n",
       "      <td>0.15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>47k</td>\n",
       "      <td>0.47000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52k</td>\n",
       "      <td>0.52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>66k</td>\n",
       "      <td>0.66000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52k</td>\n",
       "      <td>0.52000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15k</td>\n",
       "      <td>0.15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63k</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28k</td>\n",
       "      <td>0.28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>79k</td>\n",
       "      <td>0.79000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>234</td>\n",
       "      <td>0.00234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>60k</td>\n",
       "      <td>0.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>51k</td>\n",
       "      <td>0.51000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EMI  converted_emi\n",
       "0     81k        0.81000\n",
       "1   1.07L        1.07000\n",
       "2     81k        0.81000\n",
       "3     74k        0.74000\n",
       "4     57k        0.57000\n",
       "5     56k        0.56000\n",
       "6     45k        0.45000\n",
       "7     15k        0.15000\n",
       "8     47k        0.47000\n",
       "9     52k        0.52000\n",
       "10    66k        0.66000\n",
       "11    52k        0.52000\n",
       "12    15k        0.15000\n",
       "13    63k        0.63000\n",
       "14    28k        0.28000\n",
       "15    79k        0.79000\n",
       "16    234        0.00234\n",
       "17    60k        0.60000\n",
       "18    51k        0.51000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'EMI': ['81k', '1.07L', '81k', '74k', '57k', '56k', '45k', '15k', '47k', '52k', \n",
    "            '66k', '52k', '15k', '63k', '28k', '79k', '234', '60k', '51k']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Conversion to lakh\n",
    "converted_emi = []\n",
    "\n",
    "for emi in df['EMI']:\n",
    "    if 'k' in emi:\n",
    "        # Convert from thousands to lakhs\n",
    "        converted_emi.append(float(emi.replace('k', '')) / 100)\n",
    "    elif 'L' in emi:\n",
    "        # No change needed for lakh\n",
    "        converted_emi.append(float(emi.replace('L', '')))\n",
    "    else:\n",
    "        # Convert rupees to lakhs\n",
    "        converted_emi.append(float(emi) / 100000)\n",
    "\n",
    "# Add the converted values to the DataFrame\n",
    "df['converted_emi'] = converted_emi\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9935bcb6-a0be-437b-9540-ae6b80fa677d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6*100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3451b513-0d31-4223-859d-f8df548a820e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "list1 = [\n",
    "    \"cardid73032233\", \"cardid72658797\", \"cardid72658797\", \"cardid72658797\",\n",
    "    \"cardid72658797\", \"cardid72658797\", \"cardid73032229\", \"cardid73032231\",\n",
    "    \"cardid72658797\", \"cardid72828095\", \"cardid72658797\", \"cardid73032229\",\n",
    "    \"cardid71315131\", \"cardid72828095\", \"cardid72658797\", \"cardid72658797\",\n",
    "    \"cardid72658797\", \"cardid73032229\", \"cardid73032231\", \"cardid73032229\",\n",
    "    \"cardid72362469\"\n",
    "]\n",
    "\n",
    "list2 = [\n",
    "    \"cardid72674109\", \"cardid72727949\", \"cardid72474661\", \"cardid72815855\",\n",
    "    \"cardid73098635\", \"cardid72953259\", \"cardid72288081\", \"cardid72284483\",\n",
    "    \"cardid72284713\"\n",
    "]\n",
    "\n",
    "# Find common IDs between the two lists\n",
    "common_ids = set(list1).intersection(list2)\n",
    "\n",
    "# Print common IDs\n",
    "print(common_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f970a-5c05-4662-8645-d46267b5921c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of rows in the DataFrame that do not contain any null values.\n",
    "df.notna().all(axis=1).sum()\n",
    "(df.isnull().sum(axis=1) > 2).sum()\n",
    "f_df = df[df.isnull().sum(axis=1) < 3]\n",
    "f_df.shape\n",
    "f_df.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e0735-6202-41fb-83a0-24aa65a2709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['ID'] == 'cardid73099275', 'flat_on_floor'] = np.nan\n",
    "#df.loc[df['ID'] == 'cardid73099275', ['bath','flat_on_floor']] = df.loc[df['ID'] == 'cardid73099275', ['bath','flat_on_floor']].fillna(value = {'bath': 2,'flat_on_floor':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6709b92-04cb-4c06-b3e5-ee1d9389f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lift of this ID is 2\n",
    "ids_to_update = [\n",
    "    \"cardid71631505\",\n",
    "    \"cardid71631467\",\n",
    "    \"cardid71631499\",\n",
    "    \"cardid71631509\",\n",
    "    \"cardid71631481\",\n",
    "    \"cardid71631485\",\n",
    "    \"cardid72323111\"\n",
    "]\n",
    "\n",
    "# Update 'lift' column for matching IDs\n",
    "#df.loc[df['ID'].isin(ids_to_update), 'lift'] = 2\n",
    "\n",
    "# Verify the changes\n",
    "#df[df['ID']== 'cardid71631509']['lift']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6408cfbd-b0cb-4350-8695-7443f6230858",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd_flooring\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd_flooring\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloor3\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmd_flooring\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['floor1'] = df['md_flooring'].str.split(',').str[0]\n",
    "df['floor2'] = df['md_flooring'].str.split(',').str[1]\n",
    "df['floor3'] = df['md_flooring'].str.split(',').str[2]\n",
    "df['floor4'] = df['md_flooring'].str.split(',').str[3]\n",
    "df['floor5'] = df['md_flooring'].str.split(',').str[4]\n",
    "df['floor6'] = df['md_flooring'].str.split(',').str[5]\n",
    "df['floor7'] = df['md_flooring'].str.split(',').str[6]\n",
    "df['floor8'] = df['md_flooring'].str.split(',').str[7]\n",
    "\n",
    "#find the unique values from all above column combiningly \n",
    "\n",
    "# Combine all floor columns into a single array\n",
    "all_floors = pd.concat([df[f'floor{i}'] for i in range(1, 9)]).str.strip().dropna().values\n",
    "# Find unique values\n",
    "unique_floors = np.unique(all_floors)\n",
    "print(unique_floors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f016f5fb-4643-4c92-9575-78ae642ecc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a9d662-37a6-45f7-ad22-d97f61285ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chk mcar or not using chi square test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a missingness indicator (1 if missing, 0 if not missing)\n",
    "missing_indicators = df.isna().astype(int)\n",
    "\n",
    "# Perform a Chi-Square test between missing values in 'bath' and missing values in 'parking'\n",
    "contingency_table = pd.crosstab(missing_indicators['bath'], missing_indicators['parking'])\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "print(f\"Chi-Square Test Statistic: {chi2_stat}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Missingness is not MCAR.\")\n",
    "else:\n",
    "    print(\"Missingness is MCAR.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74810502-bdf0-4ee4-8f4a-b7400d1795a9",
   "metadata": {},
   "source": [
    "# extra_room work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e86cf-5822-4f7e-ac16-71ccfe2a037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle NaN values explicitly and split entries by commas\n",
    "unique_floorings = set()\n",
    "\n",
    "for flooring_list in df['extra_rooms']:\n",
    "    if pd.isna(flooring_list):\n",
    "        unique_floorings.add('NaN')  # Include 'NaN' as a special category\n",
    "    else:\n",
    "        unique_floorings.update(flooring.strip() for flooring in flooring_list.split(','))\n",
    "\n",
    "# Convert to a sorted list for better readability\n",
    "unique_floorings = sorted(unique_floorings)\n",
    "\n",
    "# Print the unique flooring types\n",
    "print(unique_floorings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "636e875f-07c8-4522-9f8d-2cd9f470e774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   project_id  value  id  cumsum_value\n",
      "0           1    100   1           150\n",
      "1           2    200   2           250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Left DataFrame\n",
    "left_df = pd.DataFrame({\n",
    "    \"project_id\": [1, 2, 3],\n",
    "    \"value\": [100, 200, 300]\n",
    "})\n",
    "\n",
    "# Right DataFrame\n",
    "right_df = pd.DataFrame({\n",
    "    \"id\": [1, 2, 4],\n",
    "    \"cumsum_value\": [150, 250, 400]\n",
    "})\n",
    "\n",
    "# Merging on different column names\n",
    "merged_df = left_df.merge(\n",
    "    right_df, \n",
    "    left_on=\"project_id\",  # Column in left_df\n",
    "    right_on=\"id\",         # Column in right_df\n",
    "    how=\"inner\"            # Inner join\n",
    ")\n",
    "\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bfed715-7c21-4151-bc99-1fd4d4cc0a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  project_name  value  cumsum_value\n",
      "0    Project A    100           150\n",
      "1    Project B    200           250\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data for filtered_df\n",
    "data_filtered = {\n",
    "    \"project_name\": [\"Project A\", \"Project B\", \"Project C\"],\n",
    "    \"value\": [100, 200, 300]\n",
    "}\n",
    "filtered_df = pd.DataFrame(data_filtered)\n",
    "\n",
    "# Sample data for project_cumsum\n",
    "data_cumsum = {\n",
    "    \"project_name\": [\"Project A\", \"Project B\", \"Project D\"],\n",
    "    \"cumsum_value\": [150, 250, 400]\n",
    "}\n",
    "project_cumsum = pd.DataFrame(data_cumsum)\n",
    "\n",
    "# Merging the DataFrames\n",
    "merged_df = filtered_df.merge(\n",
    "    project_cumsum, \n",
    "    left_on='project_name', \n",
    "    right_on='project_name', \n",
    "    how='inner'  # Only rows with matching project_name will be merged\n",
    ")\n",
    "\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0431a3f-4dcb-4b26-9ab9-13b7c21042c3",
   "metadata": {},
   "source": [
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821c471a-64b9-416a-a4ee-8e8d42f732e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choropleth Map Using folium\n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Remove rows with NaN values in 'lattitude', 'longitude', or 'price'\n",
    "df_locate = df.dropna(subset=['lattitude', 'longitude', 'price'])\n",
    "\n",
    "# Initialize the map centered around Mumbai region\n",
    "m = folium.Map(location=[19.0, 73.0], zoom_start=10)\n",
    "\n",
    "# Add a heatmap layer based on prices\n",
    "heat_data = [[row['lattitude'], row['longitude'], row['price']] for index, row in df_locate.iterrows()]\n",
    "HeatMap(heat_data, radius=15, blur=10).add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m.save(\"price_heatmap.html\")\n",
    "print(\"Choropleth map saved as 'price_heatmap.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1086ec4-f9bc-4ba3-a133-fd3125e2c7ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Pivot data to create a matrix for heatmap\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Replace this with actual latitude/longitude bins if needed\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df_heatmap \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mpivot_table(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m, values\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, aggfunc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot heatmap\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#heatmap using seaborn \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pivot data to create a matrix for heatmap\n",
    "# Replace this with actual latitude/longitude bins if needed\n",
    "df_heatmap = df.pivot_table(index='region', values='price', aggfunc='mean')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df_heatmap, annot=True, cmap='YlGnBu', fmt='.2f')\n",
    "plt.title(\"Heatmap of Average Property Prices by Region\")\n",
    "plt.xlabel(\"Regions\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bf9272-e257-461e-a0f4-31a58e02bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choropleth Using plotly\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Example data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a choropleth map\n",
    "fig = px.scatter_mapbox(\n",
    "    df, lat='latitude', lon='longitude', color='price',\n",
    "    size='price', color_continuous_scale=\"Viridis\",\n",
    "    hover_name='region', zoom=9, height=500\n",
    ")\n",
    "\n",
    "# Set the map style\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(title=\"Geographical Price Trends\")\n",
    "\n",
    "# Display the map\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8df7a07-2fd6-4f7c-bbc7-f2956f99ce64",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chk_area_d.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchk_area_d.csv\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your CSV file path\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Ensure the necessary columns exist\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chk_area_d.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'chk_area_d.csv'  # Replace with your CSV file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the necessary columns exist\n",
    "if 'url' not in df.columns or 'id' not in df.columns:\n",
    "    raise ValueError(\"The CSV file must contain 'url' and 'id' columns.\")\n",
    "\n",
    "# Define a function to check URL accessibility\n",
    "def check_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # 5-second timeout\n",
    "        return response.status_code == 200  # Return True if status code is 200\n",
    "    except requests.RequestException:\n",
    "        return False  # Return False if any error occurs\n",
    "\n",
    "# Filter rows where the URL is accessible\n",
    "accessible_ids = []\n",
    "for index, row in df.iterrows():\n",
    "    url = row['url']\n",
    "    if check_url(url):  # Check if the URL is accessible\n",
    "        accessible_ids.append(row['id'])\n",
    "\n",
    "# Output the result\n",
    "print(\"Accessible IDs:\", accessible_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e345fd09-fdec-4a5d-9f80-91885c22fd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                id                                                url  \\\n",
      "0   cardid72534377  https://www.magicbricks.com/propertydetails/3-...   \n",
      "1   cardid72457585  https://www.magicbricks.com/propertydetails/3-...   \n",
      "2   cardid71273837  https://www.magicbricks.com/propertydetails/4-...   \n",
      "3   cardid72610829  https://www.magicbricks.com/propertydetails/2-...   \n",
      "4   cardid72413197  https://www.magicbricks.com/propertydetails/6-...   \n",
      "5   cardid71378387  https://www.magicbricks.com/propertydetails/3-...   \n",
      "6   cardid68506935  https://www.magicbricks.com/propertydetails/6-...   \n",
      "7   cardid70968555  https://www.magicbricks.com/propertydetails/6-...   \n",
      "8   cardid69234709  https://www.magicbricks.com/propertydetails/4-...   \n",
      "9   cardid71707037  https://www.magicbricks.com/propertydetails/6-...   \n",
      "10  cardid64903111  https://www.magicbricks.com/propertydetails/3-...   \n",
      "11  cardid71713921  https://www.magicbricks.com/propertydetails/3-...   \n",
      "12  cardid57396717  https://www.magicbricks.com/propertydetails/3-...   \n",
      "13  cardid72476991  https://www.magicbricks.com/propertydetails/3-...   \n",
      "14  cardid72558151  https://www.magicbricks.com/propertyDetails/2-...   \n",
      "\n",
      "                                              address  bed   price  \\\n",
      "0   panvel, navi mumbai - central navi mumbai, mah...    3   1.600   \n",
      "1   juinagar, navi mumbai - central navi mumbai, m...    3   2.900   \n",
      "2   kharghar, navi mumbai - central navi mumbai, m...    4   2.790   \n",
      "3   vasai west, mumbai - mira road and beyond, mah...    2   0.822   \n",
      "4   rajendra nagar, borivali east, mumbai - wester...    6  10.000   \n",
      "5   runwal bliss, near kanjurmarg railway station,...    3   3.140   \n",
      "6   near ecole world school., juhu, mumbai - weste...    6  25.000   \n",
      "7   gulmohar road jvpd scheme, juhu, mumbai - west...    6  15.250   \n",
      "8   hiranandani gardens, mumbai, powai, mumbai - c...    4   8.250   \n",
      "9   oberoi sky city, off western express highway, ...    6   9.500   \n",
      "10  chembur, mumbai, chembur, mumbai - harbour lin...    3   3.400   \n",
      "11  kharghar, navi mumbai, kharghar, navi mumbai -...    3   1.370   \n",
      "12  mulund west, mumbai, mulund west, mumbai - cen...    3   2.530   \n",
      "13  shreenath apartment sm road opp krc kandivali ...    3   3.550   \n",
      "14                                              malad    2   3.330   \n",
      "\n",
      "    costpersqft  area  area_from_url  area_difference  \n",
      "0         14260  1122           1810             -688  \n",
      "1         23673  1225           2000             -775  \n",
      "2         18058  1545           2601            -1056  \n",
      "3         21409   384           1200             -816  \n",
      "4         48876  2046           3300            -1254  \n",
      "5         28940  1085           1730             -645  \n",
      "6         58140  4300           6000            -1700  \n",
      "7         61492  2480           3472             -992  \n",
      "8         49254  1675           2500             -825  \n",
      "9         43182  2200           3100             -900  \n",
      "10        30797  1104           1821             -717  \n",
      "11        13980   980           1650             -670  \n",
      "12        24095  1050           1675             -625  \n",
      "13        34004  1044           1670             -626  \n",
      "14        23232  2323           1232             -555  \n",
      "Accessible IDs: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'delete (2).xlsx'  # Replace with your Excel file path\n",
    "sheet_name = 'Sheet1'  # Replace with your sheet name if needed\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "print(df)\n",
    "\n",
    "# Ensure the necessary columns exist\n",
    "if 'url' not in df.columns or 'id' not in df.columns or 'area_difference' not in df.columns:\n",
    "    raise ValueError(\"The Excel file must contain 'url', 'id', and 'area_difference' columns.\")\n",
    "\n",
    "# Filter rows with negative 'area_difference'\n",
    "filtered_df = df[df['area_difference'] < 0]\n",
    "\n",
    "# Define a function to check URL accessibility\n",
    "def check_url(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # 5-second timeout\n",
    "        return response.status_code == 200  # Return True if status code is 200\n",
    "    except requests.RequestException:\n",
    "        return False  # Return False if any error occurs\n",
    "\n",
    "# Filter rows where the URL is accessible\n",
    "accessible_ids = []\n",
    "for index, row in filtered_df.iterrows():\n",
    "    url = row['url']\n",
    "    if check_url(url):  # Check if the URL is accessible\n",
    "        accessible_ids.append(row['id'])\n",
    "\n",
    "# Output the result\n",
    "print(\"Accessible IDs:\", accessible_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97352141-85a6-4153-a218-8420cb22887a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
